{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3f6612-5fa7-4189-a4e7-612df5321a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import MapType, StringType, ArrayType, IntegerType, StructType, StructField\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import boto3\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e55d8e-13d2-4e00-95c5-0a711b3b8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = 'reddit-tifu'\n",
    "AWS_ACCESS_KEY_ID = '**'\n",
    "AWS_SECRET_ACCESS_KEY = '**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36dd24c3-a730-41b5-8df4-feca142b16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark(appname, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY):\n",
    "    conf = SparkConf()\n",
    "    \n",
    "    conf.setAll([\n",
    "        (\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\"),\n",
    "        (\"spark.hadoop.fs.s3a.access.key\", AWS_ACCESS_KEY_ID),\n",
    "        (\"spark.hadoop.fs.s3a.secret.key\", AWS_SECRET_ACCESS_KEY)\n",
    "    ])\n",
    "    \n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(conf=conf) \\\n",
    "        .appName(appname) \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca29721-9077-48dd-8489-d21fbf7dc45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/.local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f1b32e4b-19e0-4713-8f80-bd5b9cc05b1e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 286ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f1b32e4b-19e0-4713-8f80-bd5b9cc05b1e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/9ms)\n",
      "25/04/15 22:28:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark(\"data prep\", AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1857df77-7c8a-4009-b0cd-0b6c47a9b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/15 22:28:51 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(f\"s3a://{s3_bucket}/reddit_tifu_llm.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d59ff0-c250-42bb-a2c1-03109ea740fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Prompt                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Text: I was on Skype on my tablet as I went to the toilet IMing a friend. I don't multitask very well, so I forgot one of the most important things to do before pooping. I think the best part was when I realised and told my mate who just freaked out because I was talking to him on the John! \\nTitle: forgetting to pull my underwear down before i pooped. ####|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b7184fc-4ce1-4bf9-a026-9874831aa12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections(prompt):\n",
    "    split_prompt = prompt.split(\" \\nTitle: \")\n",
    "    text = split_prompt[0]\n",
    "    text = text.replace('Text: ', '')\n",
    "    title = split_prompt[1].split(\" ####\")[0]\n",
    "    return {\n",
    "    \"text\": text,\n",
    "    \"title\": title\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b6c410-61d2-4eff-b54b-d12e7948bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|AnnotatedSections                                                                                                                                                                                                                                                                                                                                                      |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|{title -> forgetting to pull my underwear down before i pooped., text -> I was on Skype on my tablet as I went to the toilet IMing a friend. I don't multitask very well, so I forgot one of the most important things to do before pooping. I think the best part was when I realised and told my mate who just freaked out because I was talking to him on the John!}|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "extract_sections_udf = udf(extract_sections, MapType(StringType(), StringType()))\n",
    "annotated_df = df.withColumn(\"AnnotatedSections\", extract_sections_udf(df[\"Prompt\"]))\n",
    "annotated_df.select(\"AnnotatedSections\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d075cd-8f19-40c3-879d-c333c9664067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c5f4e5-a2af-443c-b5f6-ce11a2449ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_ids_attention_mask(prompt):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "    token_ids_dict = {}\n",
    "    attention_mask_dict = {}\n",
    "    \n",
    "    for section in prompt.keys():\n",
    "        sentence = prompt[section]\n",
    "        inputs = tokenizer(sentence, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "        token_ids_dict[section] = inputs['input_ids'].tolist()[0]\n",
    "        attention_mask_dict[section] = inputs['attention_mask'].tolist()[0]\n",
    "\n",
    "    tokens = {}\n",
    "    for section in prompt.keys():\n",
    "        tokens[section] = [tokenizer.decode(token) for token in token_ids_dict[section]]\n",
    "\n",
    "    for section in prompt.keys():\n",
    "        assert len(token_ids_dict[section]) == len(attention_mask_dict[section]) == len(tokens[section]) \n",
    "        \n",
    "    return (token_ids_dict['title'], token_ids_dict['text'], \n",
    "            attention_mask_dict['title'], attention_mask_dict['text'], \n",
    "            tokens['title'], tokens['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d68e20-b354-4643-82c5-feb093c008d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    " StructField(\"title_token_ids\", ArrayType(IntegerType()), False),\n",
    " StructField(\"text_token_ids\", ArrayType(IntegerType()), False),\n",
    " StructField(\"title_attention_mask\", ArrayType(IntegerType()), False),\n",
    " StructField(\"text_attention_mask\", ArrayType(IntegerType()), False),\n",
    " StructField(\"title_tokens\", StringType(), False),\n",
    " StructField(\"text_tokens\", StringType(), False),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a226583-0914-44fe-9d60-1dbb26dfd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_ids_attention_mask_udf = udf(tokens_to_ids_attention_mask, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38dacec-02ba-4135-9fce-7b35b621914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_ids_masks = annotated_df.withColumn(\"ids_masks_tokens\", tokens_to_ids_attention_mask_udf(annotated_df[\"AnnotatedSections\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00673d09-d27e-49bd-a22a-5c702135ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_with_ids_masks.select(\"ids_masks_tokens.title_token_ids\", \"ids_masks_tokens.text_token_ids\", \n",
    "                                    \"ids_masks_tokens.title_attention_mask\", \"ids_masks_tokens.text_attention_mask\",\n",
    "                                   \"ids_masks_tokens.title_tokens\", \"ids_masks_tokens.text_tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01de3ba5-b88a-4415-8a2f-4db2022f7c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     title_token_ids|      text_token_ids|title_attention_mask| text_attention_mask|        title_tokens|         text_tokens|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[1, 9566, 1259, 3...|[1, 306, 471, 373...|[1, 1, 1, 1, 1, 1...|[1, 1, 1, 1, 1, 1...|[<s>, forget, tin...|[<s>, I, was, on,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_final.show(1, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3898d375-ea20-4588-99e1-9c5df6cd35c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79949"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450bd69-f456-4e7e-840c-0b56c6b7b1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
