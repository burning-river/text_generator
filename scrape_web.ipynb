{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc6c1a8-1488-454b-ad84-34fcd0403a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import boto3\n",
    "import pickle\n",
    "import s3fs\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0dd253b-45fa-4c00-96e6-2aa0d416dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id ='**', \n",
    "    client_secret ='**',  \n",
    "    user_agent ='**',  \n",
    "    username ='**',  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ad7dd6-bd77-4f29-9aaa-865c6da3ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "AWS_ACCESS_KEY_ID = '**'\n",
    "AWS_SECRET_ACCESS_KEY = '**'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d8c90-3cf4-4159-82d4-56f5c076006c",
   "metadata": {},
   "source": [
    "## Read list of subreddits from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a646b99-b92c-440e-8304-e3fcf7c22729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html(bucket, txt_file, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY):\n",
    "    '''\n",
    "    read html using beautiful soup\n",
    "    '''\n",
    "    fs = s3fs.S3FileSystem(key = AWS_ACCESS_KEY_ID, secret = AWS_SECRET_ACCESS_KEY)\n",
    "    with fs.open(f'{bucket}/{txt_file}', 'rb') as file:\n",
    "        subreddit_html = file.read()   \n",
    "    soup = BeautifulSoup(subreddit_html, \"html.parser\")\n",
    "    list_html = soup.find(\"div\", {\"class\": \"md wiki\"})\n",
    "\n",
    "    return list_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e597760d-c442-4bd2-8824-030b6e571251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subreddits(html_text):\n",
    "    '''\n",
    "    search for list of subreddits\n",
    "    '''\n",
    "    subreddits_list = set()\n",
    "    for line in html_text:\n",
    "        matches = re.findall('(/r)\\/([\\w]+)', str(line))\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                subreddits_list.add(match[1].lower())\n",
    "    subreddits_list = list(subreddits_list)\n",
    "\n",
    "    return subreddits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84e94ee7-3755-4f7a-bae2-ece11879758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_html = read_html(bucket, 'subreddit_list.txt', AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "779cf790-c9e2-4887-ad21-464e010ebbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_list = find_subreddits(list_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56a8e8b1-3fab-4296-bde2-d712bf82fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['askhistorians',\n",
       " 'askreddit',\n",
       " 'trueaskreddit',\n",
       " 'askmenover30',\n",
       " 'askwomen',\n",
       " 'shittyaskscience',\n",
       " 'askredditafterdark',\n",
       " 'tooafraidtoask',\n",
       " 'asktransgender',\n",
       " 'askgaybros',\n",
       " 'nobodyasked',\n",
       " 'askouija',\n",
       " 'asksciencefiction',\n",
       " 'askculinary',\n",
       " 'askmen',\n",
       " 'collegebasketball',\n",
       " 'askhistory',\n",
       " 'asksocialscience',\n",
       " 'askengineers',\n",
       " 'askscience',\n",
       " 'askphilosophy',\n",
       " 'askdocs']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_subreddits = [ent for ent in subreddits_list if 'ask' in ent]\n",
    "qna_subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efa3b87a-d5c5-4a37-bf96-e135e700b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qna_subreddits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605adbd-6a6e-494d-9c6c-404e069b95a1",
   "metadata": {},
   "source": [
    "## Download submissions from each subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd40cf5-e6e1-43f5-b2f3-18316a1de400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with askhistorians\n",
      "Done with askreddit\n",
      "Done with trueaskreddit\n",
      "Done with askmenover30\n",
      "Done with askwomen\n",
      "Done with shittyaskscience\n",
      "Done with askredditafterdark\n",
      "Done with tooafraidtoask\n",
      "Done with asktransgender\n",
      "Done with askgaybros\n",
      "Done with nobodyasked\n",
      "Done with askouija\n",
      "Done with asksciencefiction\n",
      "Done with askculinary\n",
      "Done with askmen\n",
      "Done with collegebasketball\n",
      "Done with askhistory\n",
      "Done with asksocialscience\n",
      "Done with askengineers\n",
      "Done with askscience\n",
      "Done with askphilosophy\n",
      "Done with askdocs\n"
     ]
    }
   ],
   "source": [
    "# download subreddit submissions\n",
    "submissions = []\n",
    "for subred in qna_subreddits:\n",
    "    for submission in reddit.subreddit(subred).hot(limit=None):\n",
    "        submissions.append(submission)\n",
    "    print(f'Done with {subred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f0e516-3acd-48fb-81e1-4d12d346dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='submissions.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c34427c-1e51-4dcb-bfee-449f94f99458",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='reddit-tifu'\n",
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf30e18b-4c1d-4d19-b588-a6aa46d54837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submissions_pkl = pickle.dumps(submissions) \n",
    "# s3_resource.Object(bucket,key).put(Body=submissions_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e802ea2-a8ee-4b0f-afa7-c4b35d728a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pickle.loads(s3_resource.Bucket(bucket).Object(key).get()['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9dac5b-c631-4efb-afd2-c4ca2f659765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17327"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c53f5a-7ae0-4263-a4c5-da87ab7bc4dd",
   "metadata": {},
   "source": [
    "## Extract text from each subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55543f22-cbdf-40f2-84ca-a7a6190fe03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(sub):\n",
    "    '''\n",
    "    extract sentences from text\n",
    "    '''\n",
    "    title = sub.title\n",
    "    main_text = sub.selftext\n",
    "    sentences = re.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', main_text)\n",
    "    if title == '' or sentences == []:\n",
    "        return []\n",
    "    else:\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a22e786-7e9a-42c7-94ff-870a9c31646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/01 16:49:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8baf41c3-c2f5-4097-9269-d1ffd7236404",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 1000\n",
    "n_subsets = 1 + len(submissions)//subset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2452f928-80eb-4a50-b815-a4a6ea1cd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_extract(subset):\n",
    "    '''\n",
    "    parallelize sentence extraction\n",
    "    '''\n",
    "    rdd = sc.parallelize(subset)\n",
    "    submissions_info = rdd.map(extract_info)\n",
    "    submissions_data = submissions_info.collect()\n",
    "\n",
    "    return submissions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b253bb-cd96-42f7-84ff-5163305aa9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over batches\n",
    "for n in range(n_subsets):\n",
    "    start = n*subset_size\n",
    "    if n < n_subsets - 1:\n",
    "        end = (n + 1)*subset_size\n",
    "        subset = submissions[start: end]\n",
    "    else: \n",
    "        subset = submissions[start: ]\n",
    "        \n",
    "    submissions_data = batch_extract(subset)\n",
    "\n",
    "    submissions_pkl = pickle.dumps(submissions_data) \n",
    "    key = f'batch_data/batch_{str(n)}.pkl'\n",
    "    s3_resource.Object(bucket,key).put(Body=submissions_pkl)\n",
    "    print(f'Done with {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "752e54bd-51d7-4887-9777-2f6b4301d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save batch data in S3 bucket\n",
    "submissions_data = []\n",
    "for n in range(n_subsets):\n",
    "    key = f'batch_data/batch_{str(n)}.pkl'\n",
    "    submissions_data += pickle.loads(s3_resource.Bucket(bucket).Object(key).get()['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c64da459-4de3-4be3-a8d7-34747a49307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(submissions_data) == len(submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57210443-6cd1-4d40-823f-e4753351ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of text to dataframe\n",
    "submissions_train_df = pd.DataFrame()\n",
    "# submissions_test_df = pd.DataFrame()\n",
    "# titles = []\n",
    "train_texts = []\n",
    "# test_texts = []\n",
    "for content in submissions_data: \n",
    "    if content != [] and content != ['']:\n",
    "       # titles.append(ent[0])     \n",
    "        for ent in content:\n",
    "            train_texts.append(ent)  \n",
    "        \n",
    "       # test_texts.append(ent[2])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6fc4394-6c11-43b3-9e45-06b0ea57c68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77920"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef72673b-43d9-485c-b6bf-460a2641d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submissions_train_df['title'] = titles\n",
    "submissions_train_df['text'] = train_texts\n",
    "# submissions_test_df['text'] = test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27d071fc-8448-4545-bb28-1d2ebc6e722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Previous](https://www.reddit.com/r/AskHistori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nobody can read all the questions and answers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Previous weeks!](https://www.reddit.com/r/Ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mods *will* remove questions which we deem to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We *will* remove answers which don't include a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [Previous](https://www.reddit.com/r/AskHistori...\n",
       "1  Nobody can read all the questions and answers ...\n",
       "2  [Previous weeks!](https://www.reddit.com/r/Ask...\n",
       "3  Mods *will* remove questions which we deem to ...\n",
       "4  We *will* remove answers which don't include a..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d630be67-6118-4b2a-ba38-5ee4b35cfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f\"s3a://{bucket}/subreddits_train_data.json\"\n",
    "submissions_train_df.to_json(s3_path, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407ae516-f592-4b33-8473-cf03617d456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f\"s3a://{bucket}/subreddits_test_data.json\"\n",
    "submissions_test_df.to_json(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1ff3b-cf81-47ba-814c-0c7b47633cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
