{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc6c1a8-1488-454b-ad84-34fcd0403a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import boto3\n",
    "import pickle\n",
    "import s3fs\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0dd253b-45fa-4c00-96e6-2aa0d416dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id ='**', \n",
    "    client_secret ='**',  \n",
    "    user_agent ='**',  \n",
    "    username ='**',  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ad7dd6-bd77-4f29-9aaa-865c6da3ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials\n",
    "AWS_ACCESS_KEY_ID = '**'\n",
    "AWS_SECRET_ACCESS_KEY = '**'\n",
    "s3_bucket = '**'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345a0f3-f0af-4f13-bb0f-23ae83531fe1",
   "metadata": {},
   "source": [
    "# Read list of subreddits from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a646b99-b92c-440e-8304-e3fcf7c22729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_html(bucket, txt_file, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY):\n",
    "    '''\n",
    "    read html using beautiful soup\n",
    "    '''\n",
    "    fs = s3fs.S3FileSystem(key = AWS_ACCESS_KEY_ID, secret = AWS_SECRET_ACCESS_KEY)\n",
    "    with fs.open(f'{bucket}/{txt_file}', 'rb') as file:\n",
    "        subreddit_html = file.read()   \n",
    "    soup = BeautifulSoup(subreddit_html, \"html.parser\")\n",
    "    list_html = soup.find(\"div\", {\"class\": \"md wiki\"})\n",
    "\n",
    "    return list_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e597760d-c442-4bd2-8824-030b6e571251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subreddits(html_text):\n",
    "    '''\n",
    "    search for list of subreddits\n",
    "    '''\n",
    "    subreddits_list = set()\n",
    "    for line in html_text:\n",
    "        matches = re.findall('(/r)\\/([\\w]+)', str(line))\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                subreddits_list.add(match[1].lower())\n",
    "    subreddits_list = list(subreddits_list)\n",
    "\n",
    "    return subreddits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e94ee7-3755-4f7a-bae2-ece11879758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_html = read_html(s3_bucket, 'subreddit_list.txt', AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779cf790-c9e2-4887-ad21-464e010ebbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits_list = find_subreddits(list_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f54b3d3-1bdc-450f-b11a-7559983d1dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1774"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subreddits_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a8e8b1-3fab-4296-bde2-d712bf82fd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['askwomen',\n",
       " 'askhistory',\n",
       " 'askreddit',\n",
       " 'shittyaskscience',\n",
       " 'asksciencefiction',\n",
       " 'asktransgender',\n",
       " 'askgaybros',\n",
       " 'tooafraidtoask',\n",
       " 'askhistorians',\n",
       " 'askdocs',\n",
       " 'askscience',\n",
       " 'askphilosophy',\n",
       " 'trueaskreddit',\n",
       " 'askmen',\n",
       " 'askculinary',\n",
       " 'askouija',\n",
       " 'asksocialscience',\n",
       " 'askmenover30',\n",
       " 'collegebasketball',\n",
       " 'askengineers',\n",
       " 'askredditafterdark',\n",
       " 'nobodyasked']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_subreddits = [ent for ent in subreddits_list if 'ask' in ent]\n",
    "qna_subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efa3b87a-d5c5-4a37-bf96-e135e700b5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qna_subreddits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99816869-4eca-49c8-9500-e82263fd1992",
   "metadata": {},
   "source": [
    "# Download submissions from each subreddit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf708454-7ddd-4187-b643-d95d159affe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_topics = []\n",
    "for topic in subreddits_list:\n",
    "    if topic not in qna_subreddits:\n",
    "        other_topics.append(topic)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c34427c-1e51-4dcb-bfee-449f94f99458",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='reddit-tifu'\n",
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd40cf5-e6e1-43f5-b2f3-18316a1de400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "for ind, subred in enumerate(other_topics):\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket, Key=f'submissions_subreddit/submissions_{subred}.pkl')\n",
    "        pass\n",
    "    except:\n",
    "        if subred != 'virginsvschad':\n",
    "            submissions = []\n",
    "            for submission in reddit.subreddit(subred).hot(limit=None):\n",
    "                submissions.append(submission)\n",
    "            key=f'submissions_subreddit/submissions_{subred}.pkl'\n",
    "            \n",
    "            submissions_pkl = pickle.dumps(submissions) \n",
    "            s3_resource.Object(bucket,key).put(Body=submissions_pkl)\n",
    "            \n",
    "            print(f'Done with {subred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e802ea2-a8ee-4b0f-afa7-c4b35d728a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pickle.loads(s3_resource.Bucket(bucket).Object(key).get()['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c9dac5b-c631-4efb-afd2-c4ca2f659765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41017"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c78c6-e827-4182-94c2-d0389b5b42dd",
   "metadata": {},
   "source": [
    "# Extract text from each subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55543f22-cbdf-40f2-84ca-a7a6190fe03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(sub):\n",
    "    title = sub.title\n",
    "    main_text = sub.selftext\n",
    "    sentences = re.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', main_text)\n",
    "    if title == '' or sentences == []:\n",
    "        return []\n",
    "    else:\n",
    "        # comments = []\n",
    "        # for top_level_comment in sub.comments:\n",
    "        #     try:\n",
    "        #         comments.append((top_level_comment.body, top_level_comment.score))  \n",
    "        #     except:\n",
    "        #         comments.append(())\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a22e786-7e9a-42c7-94ff-870a9c31646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/09 17:02:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8baf41c3-c2f5-4097-9269-d1ffd7236404",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 1000\n",
    "n_subsets = 1 + len(submissions)//subset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2452f928-80eb-4a50-b815-a4a6ea1cd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_extract(subset):\n",
    "    rdd = sc.parallelize(subset)\n",
    "    submissions_info = rdd.map(extract_info)\n",
    "    submissions_data = submissions_info.collect()\n",
    "\n",
    "    return submissions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b253bb-cd96-42f7-84ff-5163305aa9da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(n_subsets):\n",
    "    start = n*subset_size\n",
    "    if n < n_subsets - 1:\n",
    "        end = (n + 1)*subset_size\n",
    "        subset = submissions[start: end]\n",
    "    else: \n",
    "        subset = submissions[start: ]\n",
    "        \n",
    "    submissions_data = batch_extract(subset)\n",
    "\n",
    "    submissions_pkl = pickle.dumps(submissions_data) \n",
    "    key = f'batch_data_2/batch_{str(n)}.pkl'\n",
    "    s3_resource.Object(bucket,key).put(Body=submissions_pkl)\n",
    "    print(f'Done with {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "752e54bd-51d7-4887-9777-2f6b4301d4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_data = []\n",
    "for n in range(n_subsets):\n",
    "    key = f'batch_data_2/batch_{str(n)}.pkl'\n",
    "    submissions_data += pickle.loads(s3_resource.Bucket(s3_bucket).Object(key).get()['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c64da459-4de3-4be3-a8d7-34747a49307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(submissions_data) == len(submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57210443-6cd1-4d40-823f-e4753351ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_train_df = pd.DataFrame()\n",
    "# submissions_test_df = pd.DataFrame()\n",
    "# titles = []\n",
    "train_texts = []\n",
    "# test_texts = []\n",
    "for content in submissions_data: \n",
    "    if content != [] and content != ['']:\n",
    "       # titles.append(ent[0])     \n",
    "        for ent in content:\n",
    "            train_texts.append(ent)  \n",
    "        \n",
    "       # test_texts.append(ent[2])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6fc4394-6c11-43b3-9e45-06b0ea57c68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85850"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef72673b-43d9-485c-b6bf-460a2641d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submissions_train_df['title'] = titles\n",
    "submissions_train_df['text'] = train_texts\n",
    "# submissions_test_df['text'] = test_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27d071fc-8448-4545-bb28-1d2ebc6e722c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another home on the eastern plains of Colorado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colorado stopped using state Medicaid funds on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here’s one of many that are now abandoned-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>More Blossoms &amp; Bandos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This house has a very interesting history.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Another home on the eastern plains of Colorado...\n",
       "1  Colorado stopped using state Medicaid funds on...\n",
       "2         Here’s one of many that are now abandoned-\n",
       "3                            More Blossoms & Bandos.\n",
       "4         This house has a very interesting history."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d630be67-6118-4b2a-ba38-5ee4b35cfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f\"s3a://{bucket}/subreddits_train_data_2.json\"\n",
    "submissions_train_df.to_json(s3_path, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "407ae516-f592-4b33-8473-cf03617d456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = f\"s3a://{bucket}/subreddits_test_data.json\"\n",
    "submissions_test_df.to_json(s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1ff3b-cf81-47ba-814c-0c7b47633cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
